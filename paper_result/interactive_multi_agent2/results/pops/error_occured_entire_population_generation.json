{
    "operator": "m1",
    "algorithm_description": "This algorithm is a hybrid RRT* planner that combines adaptive neighbor radius with bidirectional tree growth for faster convergence. It initially grows two trees from start and goal, alternating expansion between them. It uses adaptive rewiring radius shrinking as the tree grows, and switches from uniform random sampling to informed ellipsoidal sampling after finding the first feasible path to improve efficiency and path quality. Upon termination or timeout, it applies iterative path shortcutting to improve smoothness and reduce path length. The planner enforces strict collision checking and respects map bounds, returning the best found path within a hard 30-second limit.",
    "planning_mechanism": "The planner maintains two RRT* trees grown from start and goal respectively, using collision-checked incremental extensions and rewiring with adaptive neighborhood radius. Sampling is biased towards informed ellipsoidal regions after the first solution is found, improving search focus. After completion or timeout, iterative shortcutting smooths the returned path.",
    "code": "class Node:\n    def __init__(self, position, parent=None, cost=0.0):\n        self.position = position\n        self.parent = parent\n        self.cost = cost\n        self.children = []\n\n    def add_child(self, child):\n        self.children.append(child)\n\n    def remove_child(self, child):\n        if child in self.children:\n            self.children.remove(child)\n\n    def update_parent(self, new_parent, new_cost):\n        if self.parent:\n            self.parent.remove_child(self)\n        self.parent = new_parent\n        self.cost = new_cost\n        new_parent.add_child(self)\nclass Planner:\n    def __init__(self, max_iter=10000, step_size=4.0, goal_sample_rate=0.05, max_time=30.0):\n        self.max_iter = max_iter\n        self.step_size = step_size\n        self.goal_sample_rate = goal_sample_rate\n        self.max_time = max_time\n\n    def plan(self, map):\n        bounds = map.size\n        start_pos = map.start\n        goal_pos = map.goal\n        obstacles = map.obstacles\n        is_3d = len(bounds) == 3\n\n        nodes_start = [Node(start_pos)]\n        nodes_goal = [Node(goal_pos)]\n        edges = []\n\n        best_cost = float('inf')\n        best_path_endnode_start = None\n        best_path_endnode_goal = None\n        found_solution = False\n\n        start_time = time.monotonic()\n\n        def sample():\n            if found_solution:\n                # Informed sampling inside ellipsoid\n                return self._informed_sample(start_pos, goal_pos, best_cost, bounds, is_3d)\n            else:\n                if random.random() < self.goal_sample_rate:\n                    return goal_pos\n                return tuple(random.uniform(0, bounds[d]) for d in range(len(bounds)))\n\n        def nearest_node(nodes, point):\n            return min(nodes, key=lambda n: math.dist(n.position, point))\n\n        def near_nodes(nodes, point, radius):\n            return [n for n in nodes if math.dist(n.position, point) <= radius]\n\n        def steer(from_pos, to_pos):\n            dist = math.dist(from_pos, to_pos)\n            if dist <= self.step_size:\n                return to_pos\n            direction = tuple((to_pos[d] - from_pos[d]) / dist for d in range(len(from_pos)))\n            return tuple(from_pos[d] + direction[d] * self.step_size for d in range(len(from_pos)))\n\n        def collision_free_node(pos):\n            return not self._is_in_obstacle(pos, obstacles, is_3d)\n\n        def collision_free_edge(p1, p2):\n            return not self._is_edge_in_obstacle(p1, p2, obstacles, is_3d)\n\n        def try_extend(tree_nodes, other_tree_nodes):\n            if time.monotonic() - start_time > self.max_time:\n                return None, None, True  # Timeout\n\n            x_rand = sample()\n            x_near = nearest_node(tree_nodes, x_rand)\n            x_new_pos = steer(x_near.position, x_rand)\n            if not collision_free_node(x_new_pos) or not collision_free_edge(x_near.position, x_new_pos):\n                return None, None, False\n\n            # Adaptive neighbor radius\n            gamma_rrt_star = 50.0  # higher to ensure connectivity, adjust as needed\n            n = len(tree_nodes) + 1\n            dim = len(bounds)\n            radius = min(gamma_rrt_star * (math.log(n) / n) ** (1/dim), self.step_size * 15)\n\n            near = near_nodes(tree_nodes, x_new_pos, radius)\n\n            min_cost = x_near.cost + math.dist(x_near.position, x_new_pos)\n            best_parent = x_near\n            for node_near in near:\n                cost_through = node_near.cost + math.dist(node_near.position, x_new_pos)\n                if cost_through < min_cost and collision_free_edge(node_near.position, x_new_pos):\n                    min_cost = cost_through\n                    best_parent = node_near\n\n            new_node = Node(x_new_pos)\n            new_node.update_parent(best_parent, min_cost)\n            tree_nodes.append(new_node)\n            edges.append((best_parent, new_node))\n\n            # Rewire neighbors\n            for neighbor in near:\n                if neighbor is best_parent:\n                    continue\n                cost_through_new = new_node.cost + math.dist(new_node.position, neighbor.position)\n                if cost_through_new < neighbor.cost and collision_free_edge(new_node.position, neighbor.position):\n                    edges.remove((neighbor.parent, neighbor))\n                    neighbor.update_parent(new_node, cost_through_new)\n                    edges.append((new_node, neighbor))\n\n            # Try connect to other tree\n            near_other = near_nodes(other_tree_nodes, x_new_pos, radius)\n            connected_node_other = None\n            connecting_cost = float('inf')\n            for node_other in near_other:\n                if collision_free_edge(new_node.position, node_other.position):\n                    cost_connect = new_node.cost + math.dist(new_node.position, node_other.position) + node_other.cost\n                    if cost_connect < connecting_cost:\n                        connecting_cost = cost_connect\n                        connected_node_other = node_other\n\n            if connected_node_other and connecting_cost < best_cost:\n                # Update best path info\n                nonlocal best_cost, best_path_endnode_start, best_path_endnode_goal, found_solution\n                best_cost = connecting_cost\n                found_solution = True\n                if tree_nodes is nodes_start:\n                    best_path_endnode_start = new_node\n                    best_path_endnode_goal = connected_node_other\n                else:\n                    best_path_endnode_start = connected_node_other\n                    best_path_endnode_goal = new_node\n                return new_node, connected_node_other, False\n\n            return new_node, None, False\n\n        iteration = 0\n        while iteration < self.max_iter:\n            if time.monotonic() - start_time > self.max_time:\n                break\n            # Alternate tree growth\n            t1, t2 = (nodes_start, nodes_goal) if iteration % 2 == 0 else (nodes_goal, nodes_start)\n\n            new_node_t1, connect_node_t2, timeout_occurred = try_extend(t1, t2)\n            if timeout_occurred:\n                break\n            if connect_node_t2 is not None:\n                # Path found, continue to improve within time and iteration limit\n                pass\n\n            iteration += 1\n\n        # Extract best path if found\n        extracted_path = []\n        if found_solution and best_path_endnode_start and best_path_endnode_goal:\n            path_start = []\n            node = best_path_endnode_start\n            while node:\n                path_start.append(node.position)\n                node = node.parent\n            path_start.reverse()\n\n            path_goal = []\n            node = best_path_endnode_goal\n            while node:\n                path_goal.append(node.position)\n                node = node.parent\n\n            extracted_path = path_start + path_goal\n\n            # Smooth path by shortcutting iteratively\n            extracted_path = self._shortcut_path(extracted_path, obstacles, is_3d)\n\n        success_state = found_solution\n\n        # Collect all nodes from both trees\n        all_nodes = nodes_start + nodes_goal\n\n        return PlannerResult(success=success_state,\n                             path=extracted_path,\n                             nodes=all_nodes,\n                             edges=edges)\n\n    def _informed_sample(self, start, goal, c_best, bounds, is_3d):\n        # Informed sampling inside prolate hyperspheroid\n        # Reference: Gammell et al., Informed RRT*\n        if c_best == float('inf'):\n            return tuple(random.uniform(0, bounds[d]) for d in range(len(bounds)))\n\n        dim = len(start)\n        center = [(s + g) / 2 for s, g in zip(start, goal)]\n        a1 = [g - s for s, g in zip(start, goal)]\n        dist = math.dist(start, goal)\n        if dist == 0:\n            return goal\n\n        # Create rotation matrix via SVD\n        import numpy as np\n        a1 = np.array(a1)\n        a1_norm = a1 / np.linalg.norm(a1)\n        I = np.eye(dim)\n        M = np.outer(a1_norm, I[:,0])\n        U, _, Vt = np.linalg.svd(M)\n        C = U @ np.diag([1]*(dim-1)+[np.linalg.det(U) * np.linalg.det(Vt)]) @ Vt\n\n        r1 = c_best / 2.0\n        if dim > 1:\n            r2 = math.sqrt(c_best**2 - dist**2) / 2.0\n            L = np.diag([r1] + [r2]*(dim-1))\n        else:\n            L = np.array([[r1]])\n\n        while True:\n            x_ball = np.random.normal(0,1,dim)\n            norm = np.linalg.norm(x_ball)\n            if norm > 1e-10:\n                x_ball = x_ball / norm * random.random()**(1/dim)\n            else:\n                continue\n\n            x_random = C @ (L @ x_ball) + center\n            if all(0 <= x_random[d] <= bounds[d] for d in range(dim)):\n                return tuple(float(x_random[d]) for d in range(dim))\n\n    def _shortcut_path(self, path, obstacles, is_3d):\n        # Iterative path shortcutting to improve smoothness & length\n        max_attempts = 200\n        path_len = len(path)\n        if path_len < 3:\n            return path\n\n        for _ in range(max_attempts):\n            if len(path) < 3:\n                break\n            i = random.randint(0, len(path) - 3)\n            j = random.randint(i+2, len(path) -1)\n            if not self._is_edge_in_obstacle(path[i], path[j], obstacles, is_3d):\n                # Shortcut possible; remove intermediate points\n                path = path[:i+1] + path[j:]\n        return path\n\n    def _is_in_obstacle(self, pos, obstacles, is_3d):\n        for obs in obstacles:\n            if is_3d:\n                x, y, z, w, h, d = obs\n                px, py, pz = pos\n                if x <= px <= x + w and y <= py <= y + h and z <= pz <= z + d:\n                    return True\n            else:\n                x, y, w, h = obs\n                px, py = pos\n                if x <= px <= x + w and y <= py <= y + h:\n                    return True\n        return False\n\n    def _is_edge_in_obstacle(self, from_pos, to_pos, obstacles, is_3d, resolution=0.5):\n        distance = math.dist(from_pos, to_pos)\n        steps = max(1, int(distance / resolution))\n        for i in range(steps +1):\n            interp = tuple(from_pos[d] + (to_pos[d] - from_pos[d]) * (i/steps) for d in range(len(from_pos)))\n            if self._is_in_obstacle(interp, obstacles, is_3d):\n                return True\n        return False",
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nSyntaxError: name 'best_cost' is used prior to nonlocal declaration\n"
    }
}
{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e2",
    "algorithm_description": "A hybrid single-tree RRT* planner combining adaptive neighbor radius rewiring, ellipsoidal informed sampling after the first solution, and an intelligent pruning mechanism to maintain tree quality. The planner starts with uniform random sampling and transitions to focused sampling inside a prolate hyperspheroid guided by the best path length, accelerating convergence to shorter, smoother paths. It dynamically adapts rewiring radius based on tree size for efficient local optimization and prunes distant or stale nodes to reduce computational overhead. The search terminates early when no improvements occur or the time limit is reached, returning the best-found path.",
    "planning_mechanism": "Two-phase planning: Phase one grows a tree from start with uniform random sampling and adaptive rewiring to discover an initial solution. Phase two restricts sampling within an informed ellipsoidal subset defined by start, goal, and current best path cost, refining path length and smoothness. Periodic pruning removes less promising nodes beyond certain cost thresholds or distance to reduce overhead. The planner incrementally chooses parents minimizing cost with careful collision checking and rewires neighbors within an adaptive radius. Early stopping ensures efficient runtime within a hard 30-second limit.",
    "code": "class Node:\n    def __init__(self, position, parent=None, cost=0.0):\n        self.position = position\n        self.parent = parent\n        self.cost = cost\n        self.children = []\n        self.valid = True\n\n    def add_child(self, child_node):\n        self.children.append(child_node)\n\n    def remove_child(self, child_node):\n        try:\n            self.children.remove(child_node)\n        except ValueError:\n            pass\n\n    def update_parent(self, new_parent, new_cost):\n        if self.parent is not new_parent:\n            if self.parent is not None:\n                self.parent.remove_child(self)\n            self.parent = new_parent\n            self.cost = new_cost\n            if new_parent is not None:\n                new_parent.add_child(self)\n\n    def path_from_root(self):\n        path = []\n        node = self\n        while node is not None:\n            path.append(node.position)\n            node = node.parent\n        return path[::-1]\nclass Planner:\n    def __init__(self, max_iter: int=5000, step_size: float=6.0, goal_sample_rate: float=0.05,\n                 prune_interval: int=200, no_improve_iter_limit: int=300):\n        self.max_iter = max_iter\n        self.step_size = step_size\n        self.goal_sample_rate = goal_sample_rate\n        self.prune_interval = prune_interval\n        self.no_improve_iter_limit = no_improve_iter_limit\n\n    def plan(self, map):\n        import time\n        import random\n        import math\n\n        bounds = map.size\n        start = map.start\n        goal = map.goal\n        obstacles = map.obstacles\n        is_3d = len(bounds) == 3\n        dim = len(bounds)\n\n        t_start = time.monotonic()\n        time_limit = 30.0\n\n        nodes = []\n        edges = []\n\n        root = Node(start)\n        nodes.append(root)\n\n        positions = [start]\n\n        best_goal_node = None\n        best_cost = float(\"inf\")\n        found_first_solution = False\n        no_improve_counter = 0\n\n        gamma_rrt_star = 35.0  # Scaling factor for adaptive radius\n\n        def dist(a, b):\n            return math.dist(a, b)\n\n        def steer(frm, to, max_dist):\n            d = dist(frm, to)\n            if d <= max_dist:\n                return to\n            ratio = max_dist / d\n            return tuple(frm[i] + (to[i] - frm[i]) * ratio for i in range(dim))\n\n        def adaptive_radius(n_nodes):\n            if n_nodes <= 1:\n                return gamma_rrt_star\n            return min(gamma_rrt_star * (math.log(n_nodes) / n_nodes) ** (1.0 / dim), self.step_size * 20)\n\n        def edge_collision_check(p1, p2):\n            length = dist(p1, p2)\n            # Resolution scales with step size for balance between overhead and accuracy\n            resolution = max(0.5, self.step_size / 2)\n            steps = max(1, int(length / resolution))\n            for i in range(steps + 1):\n                interp = tuple(p1[d] + (p2[d] - p1[d]) * i / steps for d in range(dim))\n                if self._is_in_obstacle(interp, obstacles, is_3d):\n                    return True\n            return False\n\n        def sample_uniform():\n            return tuple(random.uniform(0, bounds[d]) for d in range(dim))\n\n        def sample_informed(start, goal, c_best, c_min):\n            # Uses an ellipsoidal informed sampling inside prolate hyperspheroid\n            import numpy as np\n\n            x_center = [(s + g) / 2 for s, g in zip(start, goal)]\n            a1 = [g - s for s, g in zip(start, goal)]\n            norm_a1 = math.sqrt(sum(x ** 2 for x in a1))\n            if norm_a1 < 1e-10:\n                # Start and goal are too close\n                return tuple(random.uniform(0, bounds[d]) for d in range(dim))\n            a1 = [x / norm_a1 for x in a1]\n\n            if c_best == float(\"inf\"):\n                # No path found yet: uniform sampling\n                return tuple(random.uniform(0, bounds[d]) for d in range(dim))\n\n            # Build rotation matrix C via SVD\n            I = np.eye(dim)\n            M = np.outer(a1, I[:,0])  # shape (dim, dim)\n            U, _, Vt = np.linalg.svd(M)\n            det_U = np.linalg.det(U)\n            det_Vt = np.linalg.det(Vt)\n            det = det_U * det_Vt\n            S = np.diag([1] * (dim -1) + [det])\n            C = U @ S @ Vt\n\n            L_diag = [c_best / 2] + [math.sqrt(c_best**2 - c_min**2) / 2] * (dim - 1)\n            L = np.diag(L_diag)\n\n            while True:\n                x_ball = np.random.normal(0,1,dim)\n                norm_ball = np.linalg.norm(x_ball)\n                if norm_ball < 1e-10:\n                    continue\n                x_ball = x_ball / norm_ball\n                r = random.random() ** (1.0 / dim)\n                x_ball = x_ball * r\n                x_rand = (C @ (L @ x_ball)) + np.array(x_center)\n                if all(0 <= x_rand[d] <= bounds[d] for d in range(dim)):\n                    return tuple(x_rand)\n\n        def prune_nodes():\n            # Remove nodes far from best path or with cost much higher than best_cost (pruning)\n            nonlocal nodes, edges, positions, best_cost, best_goal_node\n\n            if not found_first_solution:\n                return  # no pruning without a solution\n\n            max_cost_factor = 1.3  # prune nodes with cost > best_cost * factor\n            max_dist_factor = 3.0  # prune nodes farther than this times best_cost from line start-goal\n\n            new_nodes = []\n            new_positions = []\n            valid_nodes_set = set()\n\n            # Precompute unit vector of start->goal\n            start_goal_vec = [g - s for s, g in zip(start, goal)]\n            sg_norm = math.sqrt(sum(x*x for x in start_goal_vec))\n            if sg_norm < 1e-12:\n                return  # degenerate case\n\n            start_goal_unit = [x / sg_norm for x in start_goal_vec]\n\n            # Project point p onto start->goal vector to find distance from path line\n            def dist_to_line(p):\n                sp = [p[d] - start[d] for d in range(dim)]\n                proj = sum(sp[d] * start_goal_unit[d] for d in range(dim))\n                closest = [start[d] + proj * start_goal_unit[d] for d in range(dim)]\n                return math.dist(p, closest)\n\n            # Keep best_goal_node and its ancestors to avoid disconnecting path\n            good_nodes = set()\n            if best_goal_node is not None:\n                q = best_goal_node\n                while q is not None:\n                    good_nodes.add(q)\n                    q = q.parent\n\n            # Collect nodes to keep\n            for node in nodes:\n                if node in good_nodes:\n                    valid_nodes_set.add(node)\n                    continue\n                if node.cost > best_cost * max_cost_factor:\n                    continue\n                if dist_to_line(node.position) > best_cost * max_dist_factor:\n                    continue\n                valid_nodes_set.add(node)\n\n            # Rebuild nodes and edges keeping only valid nodes\n            # Also fix parent-child relationships accordingly\n            new_nodes = []\n            new_positions = []\n            # Build a map old_node -> new_node to preserve references\n            node_map = {}\n\n            for node in nodes:\n                if node in valid_nodes_set:\n                    new_node = Node(node.position, None, node.cost)\n                    node_map[node] = new_node\n                    new_nodes.append(new_node)\n                    new_positions.append(new_node.position)\n\n            # Rebuild parents and children respecting valid nodes\n            for old_node, new_node in node_map.items():\n                if old_node.parent in node_map:\n                    p_new = node_map[old_node.parent]\n                    new_node.parent = p_new\n                    p_new.add_child(new_node)\n\n            # Rebuild edges list\n            new_edges = []\n            for old_node, new_node in node_map.items():\n                if new_node.parent is not None:\n                    new_edges.append((new_node.parent, new_node))\n\n            nodes[:] = new_nodes\n            positions[:] = new_positions\n            edges[:] = new_edges\n\n            # Update best_goal_node reference if pruned\n            if best_goal_node not in node_map:\n                # lost best goal node, best_cost invalidated\n                # worsen best_cost to force more exploration\n                nonlocal found_first_solution\n                found_first_solution = False\n                best_goal_node = None\n                best_cost = float(\"inf\")\n            else:\n                best_goal_node = node_map[best_goal_node]\n                best_cost = best_goal_node.cost\n\n        iter_count = 0\n\n        while iter_count < self.max_iter:\n            if time.monotonic() - t_start > time_limit:\n                break\n\n            iter_count += 1\n\n            # Sample: before first solution uniform, after that informed ellipse\n            if not found_first_solution:\n                x_rand = sample_uniform()\n            else:\n                c_min = math.dist(start, goal)\n                x_rand = sample_informed(start, goal, best_cost, c_min)\n\n            # Goal bias sampling occasionally\n            if random.random() < self.goal_sample_rate:\n                x_rand = goal\n\n            # Nearest neighbor search - linear scan\n            nearest_idx = 0\n            dmin = dist(positions[0], x_rand)\n            for i in range(1, len(nodes)):\n                dd = dist(positions[i], x_rand)\n                if dd < dmin:\n                    dmin = dd\n                    nearest_idx = i\n            nearest_node = nodes[nearest_idx]\n\n            new_pos = steer(nearest_node.position, x_rand, self.step_size)\n\n            # Node collision check\n            if self._is_in_obstacle(new_pos, obstacles, is_3d):\n                continue\n            # Edge collision check\n            if edge_collision_check(nearest_node.position, new_pos):\n                continue\n\n            # Adaptive neighbor radius\n            n_nodes = len(nodes) + 1\n            radius = adaptive_radius(n_nodes)\n\n            # Find neighbors within radius\n            neighbor_indices = []\n            for idx, pos in enumerate(positions):\n                if dist(pos, new_pos) <= radius:\n                    neighbor_indices.append(idx)\n\n            # Choose best parent among neighbors minimizing cost + dist with collision check\n            min_cost = nearest_node.cost + dist(nearest_node.position, new_pos)\n            best_parent = nearest_node\n\n            for idx in neighbor_indices:\n                neighbor = nodes[idx]\n                tentative_cost = neighbor.cost + dist(neighbor.position, new_pos)\n                if tentative_cost < min_cost:\n                    if not edge_collision_check(neighbor.position, new_pos):\n                        min_cost = tentative_cost\n                        best_parent = neighbor\n\n            new_node = Node(new_pos)\n            new_node.update_parent(best_parent, min_cost)\n            nodes.append(new_node)\n            positions.append(new_pos)\n            edges.append((best_parent, new_node))\n\n            # Rewiring neighbors if improved by new node\n            for idx in neighbor_indices:\n                neighbor = nodes[idx]\n                if neighbor is best_parent:\n                    continue\n                alt_cost = new_node.cost + dist(new_node.position, neighbor.position)\n                if alt_cost + 1e-12 < neighbor.cost:\n                    if not edge_collision_check(new_node.position, neighbor.position):\n                        try:\n                            edges.remove((neighbor.parent, neighbor))\n                        except ValueError:\n                            pass\n                        neighbor.update_parent(new_node, alt_cost)\n                        edges.append((new_node, neighbor))\n\n            # Attempt to connect goal if close enough\n            dist_to_goal = dist(new_pos, goal)\n            if dist_to_goal <= self.step_size:\n                if (not self._is_in_obstacle(goal, obstacles, is_3d)\n                        and not edge_collision_check(new_pos, goal)):\n                    goal_node = Node(goal)\n                    goal_node.update_parent(new_node, new_node.cost + dist_to_goal)\n                    nodes.append(goal_node)\n                    positions.append(goal)\n                    edges.append((new_node, goal_node))\n\n                    if goal_node.cost + 1e-9 < best_cost:\n                        best_cost = goal_node.cost\n                        best_goal_node = goal_node\n                        found_first_solution = True\n                        no_improve_counter = 0\n                    else:\n                        no_improve_counter += 1\n            else:\n                no_improve_counter += 1\n\n            if found_first_solution and no_improve_counter >= self.no_improve_iter_limit:\n                # Early termination if no improvement for many iterations\n                break\n\n            if iter_count % self.prune_interval == 0 and found_first_solution:\n                prune_nodes()\n\n        if found_first_solution and best_goal_node is not None:\n            extracted_path = best_goal_node.path_from_root()\n            success_state = True\n        else:\n            # If no full goal reached, return path to node nearest goal\n            if len(nodes) > 0:\n                nearest_goal_node = None\n                dist_goal_min = float(\"inf\")\n                for node in nodes:\n                    d = dist(node.position, goal)\n                    if d < dist_goal_min:\n                        dist_goal_min = d\n                        nearest_goal_node = node\n                if nearest_goal_node is not None:\n                    extracted_path = nearest_goal_node.path_from_root()\n                    success_state = False\n                else:\n                    extracted_path = []\n                    success_state = False\n            else:\n                extracted_path = []\n                success_state = False\n\n        return PlannerResult(\n            success=success_state,\n            path=extracted_path,\n            nodes=nodes,\n            edges=edges\n        )\n\n    def _is_in_obstacle(self, pos, obstacles, is_3d):\n        for obs in obstacles:\n            if is_3d:\n                x, y, z, w, h, d = obs\n                px, py, pz = pos\n                if x <= px <= x + w and y <= py <= y + h and z <= pz <= z + d:\n                    return True\n            else:\n                x, y, w, h = obs\n                px, py = pos\n                if x <= px <= x + w and y <= py <= y + h:\n                    return True\n        return False",
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nSyntaxError: name 'found_first_solution' is used prior to nonlocal declaration\n"
    }
}
{
    "operator": "e2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
