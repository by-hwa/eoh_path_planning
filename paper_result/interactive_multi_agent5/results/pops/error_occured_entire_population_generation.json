{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "cross_over",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "m2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "e2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "cross_over",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "m2",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "m1",
    "algorithm_description": "An improved bidirectional RRT* planner that integrates a KD-tree for efficient nearest neighbor and radius queries, incorporates curvature-aware cost heuristics in parent selection and rewiring to enhance path smoothness, employs progressive post-processing combining adaptive shortcutting with cubic Bezier smoothing, and uses adaptive informed ellipsoidal sampling focusing the search space. These improvements collectively reduce planning time, produce shorter and smoother paths, and maintain robustness and high success rate.",
    "planning_mechanism": "The planner grows two trees from start and goal, alternating expansions. It uses a KD-tree for fast nearest neighbor and neighborhood searches. Parent selection and rewiring consider both path cost and curvature penalties to prefer smoother extensions. Sampling shifts from uniform to adaptive ellipsoidal informed sampling based on current best path cost. After connection, the path is post-processed via multiple shortcutting iterations and cubic Bezier curve smoothing to reduce jaggedness and sharp bends before returning the final solution.",
    "code": "class Node:\n    def __init__(self, position, parent=None, cost=0.0):\n        self.position = position\n        self.parent = parent\n        self.cost = cost\n        self.children = []\n    def add_child(self, child):\n        if child not in self.children:\n            self.children.append(child)\n            child.parent = self\n    def remove_child(self, child):\n        if child in self.children:\n            self.children.remove(child)\n            child.parent = None\n    def path_from_root(self):\n        path = []\n        node = self\n        while node is not None:\n            path.append(node.position)\n            node = node.parent\n        return path[::-1]\nclass Planner:\n    def __init__(self, max_iter=3000, max_no_improve=40,\n                 max_radius=18.0, min_radius=3.5,\n                 max_step=8.0, min_step=0.8,\n                 shortcut_iters=200):\n        self.max_iter = max_iter\n        self.max_no_improve = max_no_improve\n        self.max_radius = max_radius\n        self.min_radius = min_radius\n        self.max_step = max_step\n        self.min_step = min_step\n        self.shortcut_iters = shortcut_iters\n\n    def plan(self, map):\n        import random\n        import math\n        import time\n        from bisect import bisect_left, insort\n\n        bounds = tuple(map.size)\n        dim = len(bounds)\n        is_3d = (dim == 3)\n        start_p = tuple(map.start)\n        goal_p = tuple(map.goal)\n        obstacles = map.obstacles\n\n        def dist(a,b):\n            s=0.0\n            for i in range(dim):\n                d = a[i]-b[i]\n                s+=d*d\n            return math.sqrt(s)\n\n        def in_bounds(p):\n            return all(0.0<=p[i]<=bounds[i] for i in range(dim))\n\n        def in_obstacle(p):\n            px, py, pz = (p+(0.0,0.0,0.0))[:3]\n            for obs in obstacles:\n                if is_3d:\n                    ox,oy,oz,ow,oh,od = obs\n                    if ox<=px<=ox+ow and oy<=py<=oy+oh and oz<=pz<=oz+od:\n                        return True\n                else:\n                    ox,oy,ow,oh = obs\n                    if ox<=px<=ox+ow and oy<=py<=oy+oh:\n                        return True\n            return False\n\n        def edge_in_obstacle(a,b,resolution=0.5):\n            length = dist(a,b)\n            if length < 1e-14:\n                return False\n            steps = max(5, int(length/resolution))\n            for i in range(steps+1):\n                interp = tuple(a[j]+(b[j]-a[j])*i/steps for j in range(dim))\n                if in_obstacle(interp):\n                    return True\n            return False\n\n        def steer(from_p,to_p,step_size):\n            d = dist(from_p,to_p)\n            if d <= step_size:\n                return to_p\n            r = step_size/d\n            return tuple(from_p[i]+(to_p[i]-from_p[i])*r for i in range(dim))\n\n        # --- KD-tree utilities based on sorted lists per axis for node positions ---\n        class KDTree:\n            def __init__(self, points_and_nodes):\n                # points_and_nodes: list of (pos, node)\n                self.dim = dim\n                # Build sorted lists for each dimension\n                self.lists = []\n                for d_i in range(self.dim):\n                    sorted_list = sorted(points_and_nodes, key=lambda x: x[0][d_i])\n                    self.lists.append(sorted_list)\n                self.size = len(points_and_nodes)\n            def insert(self, pos, node):\n                for d_i in range(self.dim):\n                    axis_list = self.lists[d_i]\n                    # Binary insert on pos[d_i]\n                    coords = [p[0][d_i] for p in axis_list]\n                    idx = bisect_left(coords, pos[d_i])\n                    axis_list.insert(idx, (pos,node))\n                self.size += 1\n            def nearest(self, query):\n                # Approximate nearest neighbor by scanning dimension with max range\n                # Then select best among candidates\n                candidates_set = set()\n                for d_i in range(self.dim):\n                    axis_list = self.lists[d_i]\n                    coords = [p[0][d_i] for p in axis_list]\n                    idx = bisect_left(coords, query[d_i])\n                    for offset in (-1,0,1):\n                        ix = idx+offset\n                        if 0<=ix<len(axis_list):\n                            candidates_set.add(axis_list[ix][1])\n                # Compute exact best\n                best_node = None\n                best_d2 = float('inf')\n                for node in candidates_set:\n                    d2 = 0.0\n                    p = node.position\n                    for i_ in range(self.dim):\n                        diff = p[i_] - query[i_]\n                        d2 += diff*diff\n                        if d2 > best_d2:\n                            break\n                    else:\n                        if d2 < best_d2:\n                            best_node = node\n                            best_d2 = d2\n                return best_node, math.sqrt(best_d2) if best_node else None\n            def neighbors(self, query, radius):\n                r2 = radius*radius\n                neighbors_out = set()\n                for d_i in range(self.dim):\n                    axis_list = self.lists[d_i]\n                    coords = [p[0][d_i] for p in axis_list]\n                    low = query[d_i]-radius\n                    high = query[d_i]+radius\n                    low_idx = bisect_left(coords, low)\n                    high_idx = bisect_left(coords, high+1e-10)\n                    for idx in range(low_idx, high_idx):\n                        node = axis_list[idx][1]\n                        if node in neighbors_out:\n                            continue\n                        p = node.position\n                        d2 = 0.0\n                        for i_ in range(self.dim):\n                            diff = p[i_] - query[i_]\n                            d2 += diff*diff\n                            if d2 > r2:\n                                break\n                        else:\n                            neighbors_out.add(node)\n                return list(neighbors_out)\n\n        # Curvature angle helper\n        def vector_sub(a,b):\n            return [a[i]-b[i] for i in range(len(a))]\n        def curvature_angle(p1,p2,p3):\n            v1 = vector_sub(p2,p1)\n            v2 = vector_sub(p3,p2)\n            norm1 = math.sqrt(sum(x*x for x in v1))\n            norm2 = math.sqrt(sum(x*x for x in v2))\n            if norm1<1e-14 or norm2<1e-14:\n                return 0.0\n            dot = sum(v1[i]*v2[i] for i in range(len(a:=p1)))\n            val = max(-1.0,min(1.0,dot/(norm1*norm2)))\n            return math.acos(val)\n\n        # Adaptive radius for rewiring based on number nodes and iteration\n        def adaptive_radius(num_nodes,iteration):\n            if num_nodes<=1:\n                return self.max_radius\n            base = self.max_radius*((math.log(num_nodes)/num_nodes)**(1/dim))\n            factor = max(0.0,1.0-iteration/self.max_iter)\n            radius = base*factor\n            return max(self.min_radius,min(self.max_radius,radius))\n\n        # Sampling inside the map with or without ellipsoidal informed region\n        def sample(best_cost, found_solution):\n            if not found_solution or best_cost == float('inf'):\n                for _ in range(50):\n                    candidate = tuple(random.uniform(0,bounds[i]) for i in range(dim))\n                    if not in_obstacle(candidate):\n                        return candidate\n                # fallback uniform\n                while True:\n                    candidate = tuple(random.uniform(0,bounds[i]) for i in range(dim))\n                    if not in_obstacle(candidate):\n                        return candidate\n            # informed ellipsoid sampling\n            center = tuple(0.5*(start_p[i]+goal_p[i]) for i in range(dim))\n            diff = [goal_p[i]-start_p[i] for i in range(dim)]\n            dist_sg = dist(start_p,goal_p)\n            if dist_sg<1e-14:\n                return sample(float('inf'), False)\n            unit_vec = [d/dist_sg for d in diff]\n\n            # Build orthonormal basis U by Gram-Schmidt\n            U = [unit_vec]\n            for idx in range(dim-1):\n                v = [0.0]*dim\n                v[(idx+1)%dim] = 1.0\n                for u in U:\n                    proj = sum(v[j]*u[j] for j in range(dim))\n                    for j in range(dim):\n                        v[j] -= proj*u[j]\n                norm_v = math.sqrt(sum(x*x for x in v))\n                if norm_v>1e-14:\n                    U.append([x/norm_v for x in v])\n                else:\n                    U.append([0.0]*dim)\n            r1 = best_cost*0.5\n            val = best_cost*best_cost - dist_sg*dist_sg\n            r2 = math.sqrt(max(0.0,val))*0.5\n            radii = [r1]+[r2]*(dim-1)\n\n            for _ in range(50):\n                x_ball = [random.gauss(0,1) for _ in range(dim)]\n                norm_x = math.sqrt(sum(x*x for x in x_ball))\n                if norm_x<1e-14:\n                    continue\n                x_unit = [x/norm_x for x in x_ball]\n                r = random.random()**(1/dim)\n                ps = [r*radii[i]*x_unit[i] for i in range(dim)]\n                sample_p = [center[j] for j in range(dim)]\n                for i_ in range(dim):\n                    for j_ in range(dim):\n                        sample_p[j_] += U[i_][j_]*ps[i_]\n                candidate = tuple(sample_p)\n                if all(0.0<=candidate[i]<=bounds[i] for i in range(dim)) and not in_obstacle(candidate):\n                    return candidate\n            # fallback\n            while True:\n                candidate = tuple(random.uniform(0,bounds[i]) for i in range(dim))\n                if not in_obstacle(candidate):\n                    return candidate\n\n        # Parent choice with curvature-aware cost (cost + alpha*angle penalty)\n        def choose_parent(tree_nodes, tree_kdtree, pos, iteration):\n            radius = adaptive_radius(len(tree_nodes), iteration)\n            nbrs = tree_kdtree.neighbors(pos, radius)\n            nearest_node, nearest_d = tree_kdtree.nearest(pos)\n            if nearest_node is None:\n                return None, []\n            alpha = 0.3  # curvature penalty weight\n            best_parent = nearest_node\n            best_cost = nearest_node.cost + dist(nearest_node.position, pos)\n            # Calculate curvature penalty if possible\n            def angle_penalty(candidate, p):\n                if candidate.parent is None:\n                    return 0.0\n                return curvature_angle(candidate.parent.position, candidate.position, p)\n            best_cost += alpha * angle_penalty(nearest_node, pos)\n            for candidate in nbrs:\n                # collision check edge\n                if edge_in_obstacle(candidate.position, pos):\n                    continue\n                base_cost = candidate.cost + dist(candidate.position, pos)\n                penalty = 0.0\n                if candidate.parent is not None:\n                    penalty = curvature_angle(candidate.parent.position, candidate.position, pos)\n                cost_candidate = base_cost + alpha * penalty\n                if cost_candidate < best_cost:\n                    best_cost = cost_candidate\n                    best_parent = candidate\n            new_node = Node(pos)\n            best_parent.add_child(new_node)\n            new_node.cost = best_parent.cost + dist(best_parent.position, pos)\n            tree_nodes.append(new_node)\n            tree_kdtree.insert(pos, new_node)\n            return new_node, nbrs\n\n        # Rewiring neighbors with curvature consideration\n        def rewire(new_node, neighbors_nodes):\n            alpha = 0.3\n            for nb in neighbors_nodes:\n                if nb == new_node.parent or nb == new_node:\n                    continue\n                if edge_in_obstacle(new_node.position, nb.position):\n                    continue\n                base_cost = new_node.cost + dist(new_node.position, nb.position)\n                penalty = 0.0\n                if new_node.parent is not None:\n                    penalty = curvature_angle(new_node.parent.position, new_node.position, nb.position)\n                alt_cost = base_cost + alpha * penalty\n                if alt_cost < nb.cost:\n                    if nb.parent:\n                        nb.parent.remove_child(nb)\n                    new_node.add_child(nb)\n                    nb.cost = alt_cost\n\n        # Attempt connect between trees by steering and incremental addition with curvature-aware rewiring\n        def attempt_connect(tree_nodes, tree_kdtree, new_node, iteration):\n            nearest_node, nearest_dist = tree_kdtree.nearest(new_node.position)\n            if nearest_node is None:\n                return None\n            dist_to_target = dist(nearest_node.position, new_node.position)\n            step_size = max(self.min_step, self.max_step*(1.0 - iteration/self.max_iter))\n            if dist_to_target <= step_size:\n                if (not edge_in_obstacle(nearest_node.position, new_node.position) and\n                    not in_obstacle(new_node.position)):\n                    connect_node = Node(new_node.position)\n                    connect_node.cost = nearest_node.cost + dist_to_target\n                    nearest_node.add_child(connect_node)\n                    tree_nodes.append(connect_node)\n                    tree_kdtree.insert(connect_node.position, connect_node)\n                    return connect_node\n                return None\n            current = nearest_node\n            steps = int(math.ceil(dist_to_target/step_size))\n            for _ in range(steps):\n                next_pos = steer(current.position, new_node.position, step_size)\n                if (not in_bounds(next_pos) or in_obstacle(next_pos) or\n                    edge_in_obstacle(current.position, next_pos)):\n                    return None\n                candidate_node, nbrs = choose_parent(tree_nodes, tree_kdtree, next_pos, iteration)\n                if candidate_node is None:\n                    return None\n                rewire(candidate_node, nbrs)\n                if dist(candidate_node.position, new_node.position) <= step_size:\n                    if (not edge_in_obstacle(candidate_node.position, new_node.position) and\n                        not in_obstacle(new_node.position)):\n                        final_node = Node(new_node.position)\n                        final_node.cost = candidate_node.cost + dist(candidate_node.position, new_node.position)\n                        candidate_node.add_child(final_node)\n                        tree_nodes.append(final_node)\n                        tree_kdtree.insert(final_node.position, final_node)\n                        return final_node\n                    return None\n                current = candidate_node\n            return None\n\n        # Merge paths from two nodes (start tree node to root and goal tree node to root reversed)\n        def merge_paths(node_start, node_goal, expanded_from_start):\n            path_start = node_start.path_from_root()\n            path_goal = node_goal.path_from_root()\n            if expanded_from_start:\n                if path_start[-1]==path_goal[-1]:\n                    return path_start + path_goal[-2::-1]\n                else:\n                    return path_start + path_goal[::-1]\n            else:\n                if path_goal[-1]==path_start[-1]:\n                    return path_goal + path_start[-2::-1]\n                else:\n                    return path_goal + path_start[::-1]\n\n        # Cubic Bezier interpolation for smoothing triples of points\n        def cubic_bezier(p0,p1,p2,p3,t):\n            u = 1.0 - t\n            b = [0.0]*dim\n            for i in range(dim):\n                b[i] = (u**3)*p0[i] + 3*(u**2)*t*p1[i] + 3*u*(t**2)*p2[i] + (t**3)*p3[i]\n            return tuple(b)\n\n        # Smooth the path using cubic Bezier cubic curves between waypoints\n        def bezier_smooth_path(path, segments_per_curve=5):\n            if len(path)<4:\n                return path\n            smooth = []\n            n = len(path)\n            smooth.append(path[0])\n            for i in range(n-3):\n                p0 = path[i]\n                p1 = path[i+1]\n                p2 = path[i+2]\n                p3 = path[i+3]\n                for seg in range(1,segments_per_curve+1):\n                    t = seg/segments_per_curve\n                    b = cubic_bezier(p0,p1,p2,p3,t)\n                    smooth.append(b)\n            smooth.append(path[-1])\n            return smooth\n\n        # Shortcutting with collision checking preserving smoothness and curvature\n        def shortcut_path(path):\n            if len(path)<3:\n                return path\n            path = list(path)\n            changed = True\n            max_skip = 9\n            max_curv_increase = 0.4\n            alpha = 0.4  # penalty curvature tolerance\n            iter_count = 0\n            while changed and iter_count<self.shortcut_iters:\n                iter_count+=1\n                changed = False\n                i=0\n                while i<len(path)-2:\n                    max_j = min(len(path)-1, i+max_skip)\n                    if max_j <= i+1:\n                        i+=1\n                        continue\n                    j = random.randint(i+2,max_j)\n                    p_i = path[i]\n                    p_j = path[j]\n                    if edge_in_obstacle(p_i,p_j):\n                        i+=1\n                        continue\n                    # max curvature on old subpath\n                    subpath = path[i:j+1]\n                    old_max_curv = 0.0\n                    for k_ in range(1,len(subpath)-1):\n                        c = curvature_angle(subpath[k_-1], subpath[k_], subpath[k_+1])\n                        if c>old_max_curv:\n                            old_max_curv = c\n                    prev_node = path[i-1] if i>0 else None\n                    next_node = path[j+1] if j+1<len(path) else None\n                    curv_before = 0.0\n                    if prev_node:\n                        curv_before = curvature_angle(prev_node, p_i, p_j)\n                    curv_after = 0.0\n                    if next_node:\n                        curv_after = curvature_angle(p_i, p_j, next_node)\n                    max_new_curv = max(curv_before,curv_after)\n                    if max_new_curv <= old_max_curv + max_curv_increase:\n                        del path[i+1:j]\n                        changed = True\n                        break\n                    i+=1\n            return path\n\n        # Initialize nodes and KD-trees\n        nodes_start = [Node(start_p, cost=0.0)]\n        nodes_goal = [Node(goal_p, cost=0.0)]\n        kd_start = KDTree([(start_p, nodes_start[0])])\n        kd_goal = KDTree([(goal_p, nodes_goal[0])])\n        all_nodes = nodes_start + nodes_goal\n        edges = []  # Not used for output but kept for structure\n\n        best_path = []\n        best_cost = float('inf')\n        found_solution = False\n        no_improve_count = 0\n\n        start_time = time.time()\n\n        for iteration in range(self.max_iter):\n            expand_start = (iteration % 2 == 0)\n            tree_nodes = nodes_start if expand_start else nodes_goal\n            kdtree = kd_start if expand_start else kd_goal\n            other_nodes = nodes_goal if expand_start else nodes_start\n            other_kdtree = kd_goal if expand_start else kd_start\n\n            # Adaptive step size reduces as iterations grow\n            step_size = max(self.min_step, self.max_step*(1.0 - iteration/self.max_iter))\n            # Sample point\n            sample_p = sample(best_cost, found_solution)\n            if not in_bounds(sample_p) or in_obstacle(sample_p):\n                if found_solution:\n                    no_improve_count += 1\n                    if no_improve_count >= self.max_no_improve:\n                        break\n                continue\n\n            near_node, _ = kdtree.nearest(sample_p)\n            if near_node is None:\n                if found_solution:\n                    no_improve_count += 1\n                    if no_improve_count >= self.max_no_improve:\n                        break\n                continue\n\n            new_pos = steer(near_node.position, sample_p, step_size)\n            if (not in_bounds(new_pos) or in_obstacle(new_pos) or\n                edge_in_obstacle(near_node.position, new_pos)):\n                if found_solution:\n                    no_improve_count += 1\n                    if no_improve_count >= self.max_no_improve:\n                        break\n                continue\n\n            new_node, nbrs = choose_parent(tree_nodes, kdtree, new_pos, iteration)\n            if new_node is None:\n                if found_solution:\n                    no_improve_count += 1\n                    if no_improve_count >= self.max_no_improve:\n                        break\n                continue\n            rewire(new_node, nbrs)\n            all_nodes.append(new_node)\n\n            connect_node = attempt_connect(other_nodes, other_kdtree, new_node, iteration)\n            if connect_node:\n                candidate_path = merge_paths(new_node, connect_node, expand_start)\n                c_sum = 0.0\n                for idx in range(len(candidate_path)-1):\n                    c_sum += dist(candidate_path[idx], candidate_path[idx+1])\n                if c_sum < best_cost - 1e-7:\n                    best_cost = c_sum\n                    best_path = candidate_path\n                    found_solution = True\n                    no_improve_count = 0\n                else:\n                    if found_solution:\n                        no_improve_count +=1\n                        if no_improve_count >= self.max_no_improve:\n                            break\n            else:\n                if found_solution:\n                    no_improve_count +=1\n                    if no_improve_count >= self.max_no_improve:\n                        break\n\n        # Post-processing: multiple iterations shortcutting + Bezier smoothing + shortcutting again\n        if found_solution and len(best_path) > 3:\n            for _ in range(3):\n                best_path = shortcut_path(best_path)\n            best_path = bezier_smooth_path(best_path, segments_per_curve=7)\n            for _ in range(3):\n                best_path = shortcut_path(best_path)\n\n        if found_solution:\n            return PlannerResult(True, best_path, all_nodes, edges)\n        else:\n            return PlannerResult(False, [], all_nodes, edges)",
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nSyntaxError: assignment expression cannot be used in a comprehension iterable expression\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "m3",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "cross_over",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "m1",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": "A Dual-Tree Informed RRT* Planner leveraging KD-tree-based nearest neighbor queries and curvature-aware adaptive rewiring radius, with dynamic informed sampling and integrated multi-scale smoothing using iterative curvature minimization and path shortcutting that improve planning efficiency, path length, and smoothness robustly. The planner performs bidirectional tree growth with prioritized expansion from the less developed tree to balance exploration, applies an adaptive curvature-weighted cost for parent selection and rewiring to favor smoother connections, and uses early stopping criteria based on convergence of solution cost and stagnation. Final smoothing merges shortcutting with iterative curvature-driven path relaxation, resulting in efficient, smooth, and short solutions within bounded iteration budget.",
    "planning_mechanism": "The planner maintains two KD-trees for fast nearest and near neighbor searches, dynamically samples inside an informed ellipsoid shaped by current best solutions or globally if no solution exists, and grows trees alternately from the less progressed tree side. Parent selection and rewiring utilize a weighted sum of path cost and curvature penalty to prevent sharp turns while favoring shorter paths. The rewiring radius adapts based on node count and improved solution cost. Final path smoothing performs iterative relaxation of nodes to minimize curvature while preserving collision-free segments, combined with multi-scale shortcutting to both reduce length and enhance smoothness. The algorithm stops early if no significant path improvement occurs over a sequence of iterations, ensuring reduced planning time without sacrificing path quality.",
    "code": "class Node:\n    def __init__(self, position, parent=None, cost=0.0):\n        self.position = tuple(position)\n        self.parent = parent\n        self.cost = cost\n        self.children = []\n\n    def add_child(self, child):\n        if child not in self.children:\n            self.children.append(child)\n            child.parent = self\n\n    def remove_child(self, child):\n        if child in self.children:\n            self.children.remove(child)\n            child.parent = None\n\n    def path_from_root(self):\n        path = []\n        node = self\n        while node:\n            path.append(node.position)\n            node = node.parent\n        return path[::-1]\nclass Planner:\n    def __init__(self, max_iter=2500, step_size=6.0, n_near_const=30,\n                 max_no_improve=60, improve_tol=1e-7, shortcut_iters=250,\n                 relaxation_iters=40):\n        self.max_iter = max_iter\n        self.step_size = step_size\n        self.n_near_const = n_near_const\n        self.max_no_improve = max_no_improve\n        self.improve_tol = improve_tol\n        self.shortcut_iters = shortcut_iters\n        self.relaxation_iters = relaxation_iters\n\n    def plan(self, map) -> 'PlannerResult':\n        import math, random, time\n\n        start = tuple(map.start)\n        goal = tuple(map.goal)\n        bounds = tuple(map.size)\n        obstacles = map.obstacles\n        dim = len(bounds)\n        is_3d = (dim == 3)\n        dist = lambda a, b: math.dist(a, b)\n\n        # Efficient obstacle and edge checking\n        def in_obstacle(p):\n            px, py, pz = (p + (0, 0, 0))[:3]\n            for obs in obstacles:\n                if is_3d:\n                    ox, oy, oz, ow, oh, od = obs\n                    if (ox <= px <= ox + ow and oy <= py <= oy + oh and oz <= pz <= oz + od):\n                        return True\n                else:\n                    ox, oy, ow, oh = obs\n                    if (ox <= px <= ox + ow and oy <= py <= oy + oh):\n                        return True\n            return False\n\n        def edge_obstacle(f, t, resolution=1.0):\n            length = dist(f, t)\n            if length < 1e-14:\n                return False\n            steps = max(2, int(length / resolution))\n            for i in range(steps + 1):\n                inter = tuple(f[d] + (t[d] - f[d]) * i / steps for d in range(dim))\n                if in_obstacle(inter):\n                    return True\n            return False\n\n        def steer(frm, to):\n            d = dist(frm, to)\n            if d <= self.step_size:\n                return to\n            ratio = self.step_size / d\n            return tuple(frm[i] + (to[i] - frm[i]) * ratio for i in range(dim))\n\n        ### KD-tree for neighbor search inside planner ###\n\n        class KDTree:\n            def __init__(self, points_nodes):\n                # points_nodes: list of (position_tuple, Node)\n                self.dim = dim\n                # Build tree recursively, store nodes\n                def build(nodes_pt, depth=0):\n                    if not nodes_pt:\n                        return None\n                    axis = depth % self.dim\n                    nodes_pt.sort(key=lambda x: x[0][axis])\n                    median = len(nodes_pt)//2\n                    node = {\n                        'point': nodes_pt[median][0],\n                        'node_obj': nodes_pt[median][1],\n                        'left': build(nodes_pt[:median], depth+1),\n                        'right': build(nodes_pt[median+1:], depth+1),\n                        'axis': axis,\n                    }\n                    return node\n                self.root = build(points_nodes)\n\n            def nearest(self, point, best=None, best_dist=None):\n                # best = (best_node, best_dist)\n                def recurse(curr):\n                    if curr is None:\n                        return\n                    axis = curr['axis']\n                    here_p = curr['point']\n                    here_node = curr['node_obj']\n\n                    d_here = 0.0\n                    for i in range(self.dim):\n                        diff = here_p[i] - point[i]\n                        d_here += diff*diff\n                    if best_dist is None or d_here < best_dist:\n                        nonlocal best, best_dist\n                        best = here_node\n                        best_dist = d_here\n\n                    diff_axis = point[axis] - here_p[axis]\n                    first = curr['left'] if diff_axis < 0 else curr['right']\n                    second = curr['right'] if diff_axis < 0 else curr['left']\n\n                    recurse(first)\n\n                    if diff_axis*diff_axis < best_dist:\n                        recurse(second)\n                best = None\n                best_dist = None\n                recurse(self.root)\n                if best is None:\n                    return None, float('inf')\n                return best, math.sqrt(best_dist)\n\n            def radius_search(self, point, radius):\n                r2 = radius*radius\n                neighbors = []\n                def recurse(curr):\n                    if curr is None:\n                        return\n                    axis = curr['axis']\n                    here_p = curr['point']\n                    here_node = curr['node_obj']\n\n                    d2 = 0.0\n                    for i in range(self.dim):\n                        diff = here_p[i] - point[i]\n                        d2 += diff*diff\n                        if d2 > r2:\n                            break\n                    if d2 <= r2:\n                        neighbors.append(here_node)\n                    diff_axis = point[axis] - here_p[axis]\n                    if diff_axis < 0:\n                        recurse(curr['left'])\n                        if diff_axis*diff_axis <= r2:\n                            recurse(curr['right'])\n                    else:\n                        recurse(curr['right'])\n                        if diff_axis*diff_axis <= r2:\n                            recurse(curr['left'])\n                recurse(self.root)\n                return neighbors\n\n        def build_kdtree(tree):\n            pts_nodes = [(n.position, n) for n in tree]\n            if not pts_nodes:\n                return None\n            return KDTree(pts_nodes)\n\n        # Compute minimal distance c_min between start and goal\n        c_min = dist(start, goal)\n\n        # Sample with ellipsoidal informed method centered on best path cost c_best\n        def ellipsoid_sample(c_best, tree_sizes):\n            if c_best == float('inf'):\n                # Uniform sampling inside bounds with a small margin to avoid boundary issues\n                sample_pt = tuple(random.uniform(0.0, bounds[i]) for i in range(dim))\n                if not in_obstacle(sample_pt):\n                    return sample_pt\n                else:\n                    # fallback multiple tries\n                    for _ in range(10):\n                        spt = tuple(random.uniform(0.0, bounds[i]) for i in range(dim))\n                        if not in_obstacle(spt):\n                            return spt\n                    # last fallback: just return start (rare)\n                    return start\n            # Informed sampling within ellipsoid between start and goal, with major axis length c_best\n            center = tuple( (start[i] + goal[i])*0.5 for i in range(dim))\n            direction = [goal[i] - start[i] for i in range(dim)]\n            norm_dir = math.sqrt(sum(x*x for x in direction))\n            if norm_dir < 1e-14:\n                return tuple(random.uniform(0.0, bounds[i]) for i in range(dim))\n\n            unit_dir = [x/norm_dir for x in direction]\n\n            # Build orthonormal basis: unit_dir is first vector (e1)\n            basis = [unit_dir]\n            # Gram-Schmidt for remaining basis vectors:\n            for b_idx in range(dim-1):\n                base = [0]*dim\n                base[(b_idx+1)%dim] = 1.0\n                # Remove projection on existing basis vectors\n                for u_vec in basis:\n                    proj = sum(base[i]*u_vec[i] for i in range(dim))\n                    base = [base[i] - proj*u_vec[i] for i in range(dim)]\n                norm_base = math.sqrt(sum(x*x for x in base))\n                if norm_base < 1e-15:\n                    base = [0.0]*dim\n                else:\n                    base = [x/norm_base for x in base]\n                basis.append(base)\n\n            r1 = c_best*0.5  # major ellipse radius half-length\n            val = c_best*c_best - c_min*c_min\n            r2 = math.sqrt(val)*0.5 if val > 0 else 0.0\n            axis_radii = [r1] + [r2]*(dim-1)\n\n            max_attempts = 100\n            for _ in range(max_attempts):\n                # Sample random point in unit ball\n                x_ball = [random.gauss(0,1) for _ in range(dim)]\n                norm_b = math.sqrt(sum(x*x for x in x_ball))\n                if norm_b < 1e-15:\n                    continue\n                unit_b = [x/norm_b for x in x_ball]\n                u_r = random.random() ** (1.0/dim)\n                scaled = [unit_b[i]*u_r*axis_radii[i] for i in range(dim)]\n\n                # Rotate and translate sample point using basis\n                pt_rot = [0.0]*dim\n                for i_b in range(dim):\n                    for j_d in range(dim):\n                        pt_rot[j_d] += scaled[i_b]*basis[i_b][j_d]\n                sample = tuple(center[i] + pt_rot[i] for i in range(dim))\n\n                if all(0.0 <= sample[i] <= bounds[i] for i in range(dim)) and not in_obstacle(sample):\n                    return sample\n            # fallback uniform sampling if ellipsoidal fails\n            for _ in range(10):\n                spt = tuple(random.uniform(0.0, bounds[i]) for i in range(dim))\n                if not in_obstacle(spt):\n                    return spt\n            return start\n\n        def curvature_penalty(p_parent, p_cur, p_new):\n            # Returns angle in radians between two segments: (parent->cur) and (cur->new)\n            if p_parent is None:\n                return 0.0\n            v1 = [p_cur[i]-p_parent[i] for i in range(dim)]\n            v2 = [p_new[i]-p_cur[i] for i in range(dim)]\n            norm1 = math.sqrt(sum(x*x for x in v1))\n            norm2 = math.sqrt(sum(x*x for x in v2))\n            if norm1 < 1e-14 or norm2 < 1e-14:\n                return 0.0\n            dot = sum(v1[i]*v2[i] for i in range(dim))/(norm1*norm2)\n            dot = max(-1.0, min(1.0, dot))\n            angle = math.acos(dot)\n            return angle\n\n        def adaptive_radius(n_nodes, c_best, c_min_here):\n            gamma = self.n_near_const\n            if n_nodes <= 1:\n                return self.step_size*5.0\n            r = min((gamma*(math.log(n_nodes)/n_nodes))**(1/dim), self.step_size*8.0)\n            if c_best == float('inf'):\n                return r\n            shrink = max(0.25, c_best/(c_min_here*3.0))\n            rad = max(self.step_size*0.8, r*shrink)\n            return rad\n\n        def connect_paths(node_s, node_g):\n            path_s = node_s.path_from_root()\n            path_g = node_g.path_from_root()\n            path_g_rev = path_g[::-1]\n            # Remove duplicate vertex at connection\n            if path_s[-1] == path_g_rev[0]:\n                return path_s + path_g_rev[1:]\n            return path_s + path_g_rev\n\n        def add_node(tree, kdtree, sample_pt, nodes_all, edges, c_best, c_min):\n            nn, d_nn = kdtree.nearest(sample_pt) if kdtree else (None, float('inf'))\n            if nn is None:\n                return None\n            new_pos = steer(nn.position, sample_pt)\n            if in_obstacle(new_pos) or edge_obstacle(nn.position, new_pos):\n                return None\n\n            n_nodes = len(nodes_all)\n            radius = adaptive_radius(n_nodes, c_best, c_min)\n            nearby = kdtree.radius_search(new_pos, radius) if kdtree else []\n\n            alpha_curv = 0.055  # curvature weight: higher favors smoother but possibly longer paths\n\n            # Select best parent from nearby nodes (including nn)\n            candidates = nearby.copy()\n            if nn not in candidates:\n                candidates.append(nn)\n\n            best_parent = None\n            best_cost = float('inf')\n            best_score = float('inf')\n\n            for cand in candidates:\n                if edge_obstacle(cand.position, new_pos):\n                    continue\n                cost_cand = cand.cost + dist(cand.position, new_pos)\n                penalty = alpha_curv*curvature_penalty(cand.parent.position if cand.parent else None, cand.position, new_pos)\n                score = cost_cand + penalty\n                if score < best_score:\n                    best_score = score\n                    best_cost = cost_cand\n                    best_parent = cand\n            if best_parent is None:\n                return None\n\n            new_node = Node(new_pos)\n            best_parent.add_child(new_node)\n            new_node.cost = best_cost\n            tree.append(new_node)\n            nodes_all.append(new_node)\n            edges.append((best_parent, new_node))\n\n            # Rewiring neighbors if connecting through new_node improves cost+curvature metric\n            rewire_candidates = [n for n in nearby if n != best_parent and n != new_node]\n            for near_n in rewire_candidates:\n                alt_cost = new_node.cost + dist(new_node.position, near_n.position)\n                if alt_cost + self.improve_tol < near_n.cost and not edge_obstacle(new_node.position, near_n.position):\n                    curv_new = curvature_penalty(new_node.parent.position if new_node.parent else None, new_node.position, near_n.position)\n                    curv_old = curvature_penalty(near_n.parent.parent.position if near_n.parent and near_n.parent.parent else None,\n                                                near_n.parent.position if near_n.parent else None, near_n.position)\n                    if alpha_curv*curv_new <= alpha_curv*curv_old + 0.20:\n                        if near_n.parent:\n                            near_n.parent.remove_child(near_n)\n                            try:\n                                edges.remove((near_n.parent, near_n))\n                            except Exception:\n                                pass\n                        new_node.add_child(near_n)\n                        near_n.cost = alt_cost\n                        edges.append((new_node, near_n))\n\n            return new_node\n\n        def path_length(path):\n            l = 0.0\n            for i in range(len(path)-1):\n                l += dist(path[i], path[i+1])\n            return l\n\n        def shortcut_path(path):\n            if len(path) < 3:\n                return path\n            path = list(path)\n            changed = True\n            iter_count = 0\n            max_jump = 10 if len(path) > 15 else 6\n            while changed and iter_count < self.shortcut_iters:\n                changed = False\n                iter_count += 1\n                i = 0\n                while i < len(path)-2:\n                    max_j = min(len(path)-1, i + max_jump + random.randint(0,4))\n                    if max_j <= i+1:\n                        i += 1\n                        continue\n                    j = random.randint(i+2, max_j)\n                    if not edge_obstacle(path[i], path[j]):\n                        path = path[:i+1] + path[j:]\n                        changed = True\n                        break\n                    i += 1\n            return path\n\n        def iterative_curvature_relax(path, obstacles, iterations=40, step_relax=0.15):\n            # Applies curvature-minimizing relaxation moving interior nodes\n            # while ensuring collision-free path segments.\n            if len(path) < 4:\n                # Too short to smooth beyond shortcut\n                return path.copy()\n            path = [list(p) for p in path]  # mutable copy\n            for it in range(iterations):\n                moved = False\n                for i in range(1, len(path)-1):\n                    p_prev = path[i-1]\n                    p_curr = path[i]\n                    p_next = path[i+1]\n\n                    # Compute current curvature angle\n                    v1 = [p_curr[d]-p_prev[d] for d in range(dim)]\n                    v2 = [p_next[d]-p_curr[d] for d in range(dim)]\n                    norm1 = math.sqrt(sum(x*x for x in v1))\n                    norm2 = math.sqrt(sum(x*x for x in v2))\n                    if norm1 < 1e-14 or norm2 < 1e-14:\n                        continue\n                    # Target: move point to reduce curvature angle (make vectors more aligned)\n                    # Compute desired position as projection on line p_prev->p_next\n                    seg_vec = [p_next[d] - p_prev[d] for d in range(dim)]\n                    seg_len2 = sum(x*x for x in seg_vec)\n                    if seg_len2 < 1e-14:\n                        continue\n                    proj = sum((p_curr[d]-p_prev[d])*seg_vec[d] for d in range(dim))/seg_len2\n                    proj = max(0.0, min(1.0, proj))\n                    ideal_p = [p_prev[d] + proj*seg_vec[d] for d in range(dim)]\n\n                    # Relax toward ideal position weighted by step_relax\n                    new_p = [p_curr[d] + step_relax*(ideal_p[d] - p_curr[d]) for d in range(dim)]\n\n                    # Clamp inside bounds\n                    for d in range(dim):\n                        new_p[d] = max(0.0, min(bounds[d], new_p[d]))\n                    new_p_t = tuple(new_p)\n\n                    if in_obstacle(new_p_t):\n                        continue\n                    if edge_obstacle(p_prev, new_p_t) or edge_obstacle(new_p_t, p_next):\n                        continue\n\n                    # Accept new position\n                    path[i] = new_p\n                    moved = True\n                if not moved:\n                    break\n            return [tuple(p) for p in path]\n\n        # Initialization: two bidirectional trees\n        start_root = Node(start)\n        goal_root = Node(goal)\n        start_tree = [start_root]\n        goal_tree = [goal_root]\n        nodes_all = start_tree + goal_tree\n        edges = []\n\n        best_cost = float('inf')\n        best_path = []\n        found_solution = False\n\n        no_improve = 0\n        last_cost = float('inf')\n\n        # Start timer for potential time-based early stopping (not used explicitly here)\n        t_start = time.time()\n\n        # Helper to pick tree for expansion: expand smaller tree first (balance)\n        def pick_trees():\n            if len(start_tree) <= len(goal_tree):\n                return start_tree, goal_tree\n            return goal_tree, start_tree\n\n        for iter_n in range(self.max_iter):\n            tree_a, tree_b = pick_trees()\n\n            # Build or update kdtrees for efficient search\n            kd_a = build_kdtree(tree_a)\n            kd_b = build_kdtree(tree_b)\n            sample_pt = ellipsoid_sample(best_cost if found_solution else float('inf'), (len(tree_a), len(tree_b)))\n\n            newn = add_node(tree_a, kd_a, sample_pt, nodes_all, edges, best_cost, c_min)\n            if newn is None:\n                if found_solution:\n                    no_improve += 1\n                continue\n\n            # Try connecting to other tree\n            nn_b, dist_b = kd_b.nearest(newn.position) if kd_b else (None, float('inf'))\n            if nn_b is not None and dist_b <= self.step_size and not edge_obstacle(newn.position, nn_b.position):\n                # Proposed candidate solution path cost\n                c_cand = newn.cost + dist(newn.position, nn_b.position) + nn_b.cost\n                if c_cand + self.improve_tol < best_cost:\n                    # Extract path via newn and nn_b\n                    proposed_path = connect_paths(newn, nn_b)\n                    if len(proposed_path) >= 3:\n                        best_path = proposed_path\n                        best_cost = c_cand\n                        found_solution = True\n                        no_improve = 0\n                else:\n                    no_improve += 1\n            elif found_solution:\n                no_improve += 1\n\n            if found_solution and no_improve >= self.max_no_improve:\n                break\n\n            if found_solution and best_cost + self.improve_tol < last_cost:\n                last_cost = best_cost\n                no_improve = 0\n\n        if found_solution and len(best_path) >= 4:\n            # Progressive shortcutting and iterative curvature relaxation\n            for _ in range(3):\n                best_path = shortcut_path(best_path)\n                best_path = iterative_curvature_relax(best_path, obstacles, self.relaxation_iters, step_relax=0.12)\n            # One final shortcut to clean remaining residuals after relaxation\n            best_path = shortcut_path(best_path)\n\n        if found_solution:\n            return PlannerResult(True, best_path, nodes_all, edges)\n        else:\n            return PlannerResult(False, [], nodes_all, edges)",
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nSyntaxError: name 'best_dist' is used prior to nonlocal declaration\n"
    }
}
{
    "operator": "time_expert",
    "algorithm_description": null,
    "planning_mechanism": null,
    "code": null,
    "objective": null,
    "time_improvement": null,
    "length_improvement": null,
    "smoothness_improvement": null,
    "success_rate": null,
    "other_inf": {
        "Traceback": "Traceback (most recent call last):\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 172, in evaluate\n    fitness, results = self.__evaluate_path(code_string=code_string)\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 131, in __evaluate_path\n    result, avg_result = evaluate_with_timeout_dynamic(\n  File \"c:\\workspace\\eoh_path_planning\\eoh\\src\\eoh\\problems\\optimization\\classic_benchmark_path_planning\\run.py\", line 70, in evaluate_with_timeout_dynamic\n    raise payload\nTypeError: can only concatenate str (not \"NoneType\") to str\n"
    }
}
